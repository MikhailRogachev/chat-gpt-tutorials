{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN702TG9AcQQ/vz/wamTEsl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikhailRogachev/chat-gpt-tutorials/blob/master/uai-source/chart_gpt_uia_lecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install packages\n",
        "\n",
        "[**1. tiktoken is a fast BPE tokenizer created by OpenAI.**](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/tiktoken.html)\n",
        "\n",
        "[**2. LangChain is a framework for developing applications powered by language models.**](https://python.langchain.com/en/latest/index.html)\n",
        "\n",
        "[**3. OpenAI API**](https://platform.openai.com/docs/introduction)\n",
        "\n",
        "[**4. Chroma is the open-source embedding database.**](https://docs.trychroma.com/) Chroma makes it easy to build LLM apps by making knowledge, facts, and skills pluggable for LLMs.\n",
        "\n",
        "[**5. gspread is a Python API for Google Sheets.**](https://docs.gspread.org/en/v5.7.1/)\n",
        "\n",
        "[**6. oauth2client**](https://oauth2client.readthedocs.io/en/latest/) libraries and the core team is turning down support. We recommend you use google-auth and oauthlib. For more details on the deprecation, see oauth2client deprecation.\n",
        "\n"
      ],
      "metadata": {
        "id": "UNnsFFQD5KCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW-j4afa4YWe"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade tiktoken\n",
        "!pip -q install langchain openai chromadb\n",
        "!pip -q install gspread oauth2client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Import libraries - I\n",
        "\n",
        "The [subprocess](https://docs.python.org/3/library/subprocess.html) module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes.<br />\n",
        "The module [tempfile](https://docs.python.org/3/library/tempfile.html) creates temporary files and directories.<br />\n",
        "[Requests](https://requests.readthedocs.io/en/latest/) is an elegant and simple HTTP library for Python, built for human beings.\n",
        "\n"
      ],
      "metadata": {
        "id": "3_MgOIco5c2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, openai, tiktoken, re, tempfile, subprocess, pathlib\n",
        "import requests, gspread\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "from oauth2client.service_account import ServiceAccountCredentials"
      ],
      "metadata": {
        "id": "CQpRpBTV5jPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class gpt():\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def set_key(cls):\n",
        "        pass\n",
        "\n",
        "    def load_search_indexes(self, url:str) -> str:\n",
        "        pass\n",
        "\n",
        "    def load_prompt(self, url:str) -> str:\n",
        "        pass\n",
        "\n",
        "    def create_embedding(self, data):\n",
        "        pass\n",
        "\n",
        "    def answer(self, system, topic, temp = 1):\n",
        "        pass\n",
        "\n",
        "    def num_tokens_from_message(self, message, model = 'gpt-3.5-turbo-0301'):\n",
        "        pass\n",
        "\n",
        "    def insert_newlines(self, text:str, max_len:int = 70) -> str:\n",
        "        pass\n",
        "\n",
        "    def dialog(self):\n",
        "        pass\n",
        "\n",
        "    def answer_index(self, system, topic, search_index, temp = 1, verbose = 0):\n",
        "        pass\n",
        "\n",
        "    def get_chatgpt_ansver3(self, system, topic, search_index, temp = 1):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "BlH4a8K627nE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}